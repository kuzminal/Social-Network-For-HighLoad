version: '3.8'

services:
  reverse-proxy:
    image: traefik:v2.4
    networks:
      - social
      - social-net-dialogs_dialog
    command:
      #- "--log.level=DEBUG"
      - "--api.insecure=true"
      - "--providers.docker=true"
      - "--providers.docker.exposedbydefault=false"
      - "--entrypoints.web.address=:80"
      - "--tracing=true"
    ports:
      - "80:80"
      - "8081:8080"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    labels:
      - traefik.enable=false
  social:
    build:
      dockerfile: Dockerfile
      context: .
    entrypoint: /usr/bin/social
    restart: on-failure
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.social.rule=Host(`localhost`)"
      - "traefik.http.routers.social.rule=PathPrefix(`/user`) || PathPrefix(`/login`) || PathPrefix(`/post`) || PathPrefix(`/friend`)"
      - "traefik.http.routers.social.entrypoints=web"
    networks:
      - social
    environment:
      - PGHOST=master
      - PGPORT=5432
      - MIGR_DIR=/usr/bin/migrations
      # можно указать мастера в качестве слэйва если не настроена репликация и не поднимать еще два контейнера с БД
      #- SLAVE_HOST_PORT=db:5432
      - SLAVE_HOST_PORT=tarantool_master:3301,tarantool_slave:3301
      - TARANTOOL_HOST=tarantool_master
      - TARANTOOL_USER=user
      - TARANTOOL_PASSWORD=password
      - RABBIT_HOST=rabbitmq
      - RABBIT_USER=user
      - RABBIT_PASSWORD=password
      - KAFKA_BROKER_HOST=kafka
    ports:
      - "8080:8080"
      - "50051:50051"
    depends_on:
      - rabbitmq
      - master
      - tarantool_master
  rabbitmq:
    image: rabbitmq:3.10.7-management-alpine
    hostname: rabbitmq
    restart: always
    networks:
      - social
    environment:
      - RABBITMQ_DEFAULT_USER=user
      - RABBITMQ_DEFAULT_PASS=password
      - RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS=-rabbit log_levels [{connection,error},{default,error}] disk_free_limit 2147483648
    volumes:
      - /data/rabbitmq:/var/lib/rabbitmq
    ports:
      - "15672:15672"
      - "5672:5672"
  tarantool_master:
    build:
      dockerfile: tarantool/Dockerfile
      context: .
    image: tarantool/tarantool:2.11.0
    restart: always
    networks:
      - social
    environment:
      - TARANTOOL_USER_NAME=user
      - TARANTOOL_USER_PASSWORD=password
    ports:
      - "3301:3301"
  tarantool_slave:
    build:
      dockerfile: tarantool/Dockerfile
      context: .
    image: tarantool/tarantool:2.11.0
    restart: always
    networks:
      - social
    environment:
      - TARANTOOL_USER_NAME=user
      - TARANTOOL_USER_PASSWORD=password
      - TARANTOOL_REPLICATION=user:password@tarantool_master:3301
    ports:
      - "3302:3301"
  master:
    container_name: "${COMPOSE_PROJECT_NAME:-citus}_master"
    image: "citusdata/citus:11.3.0"
    ports: [ "${COORDINATOR_EXTERNAL_PORT:-5432}:5432" ]
    labels: [ "com.citusdata.role=Master" ]
    networks:
      - social
    environment: &AUTH
      POSTGRES_USER: "${POSTGRES_USER:-postgres}"
      POSTGRES_PASSWORD: "${POSTGRES_PASSWORD:-postgres}"
      PGUSER: "${POSTGRES_USER:-postgres}"
      PGPASSWORD: "${POSTGRES_PASSWORD:-postgres}"
      POSTGRES_HOST_AUTH_METHOD: "${POSTGRES_HOST_AUTH_METHOD:-trust}"
  worker:
    image: "citusdata/citus:11.3.0"
    labels: [ "com.citusdata.role=Worker" ]
    deploy:
      replicas: 2
    depends_on: [ manager ]
    networks:
      - social
    environment: *AUTH
    command: "/wait-for-manager.sh"
    volumes:
      - healthcheck-volume:/healthcheck
  manager:
    container_name: "${COMPOSE_PROJECT_NAME:-citus}_manager"
    image: "citusdata/membership-manager:0.3.0"
    networks:
      - social
    volumes:
      - "${DOCKER_SOCK:-/var/run/docker.sock}:/var/run/docker.sock"
      - healthcheck-volume:/healthcheck
    depends_on: [ master ]
    environment: *AUTH

  kafka:
    image: docker.io/bitnami/kafka:3.5
    networks:
      - social
    ports:
      - "9092:9092"
      - "9094:9094"
    volumes:
      - "kafka_data:/bitnami"
    environment:
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:9094
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,EXTERNAL://localhost:9094
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT,PLAINTEXT:PLAINTEXT
  kafdrop:
    image: obsidiandynamics/kafdrop
    restart: "no"
    networks:
      - social
    ports:
      - "9900:9000"
    environment:
      KAFKA_BROKERCONNECT: "kafka:9092"
      JVM_OPTS: "-Xms16M -Xmx48M -Xss180K -XX:-TieredCompilation -XX:+UseStringDeduplication -noverify"
    depends_on:
      - "kafka"

volumes:
  healthcheck-volume:
  kafka_data:
    driver: local

networks:
  social:
  social-net-dialogs_dialog:
    external: true

